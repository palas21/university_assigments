{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student informations (Max. 2 students) should be written in this cell (Student ID, Student Name).\n",
    "\n",
    "Student 1:\n",
    "\n",
    "Student 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK-3 Binary Linear Classification with Logistic Regression and Perceptron (Using Stochastic Gradient Descent)\n",
    "\n",
    "In this homework, you will implement binary classification models such as Logistic Regression and Perceptron with appropriate cost functions, and train these models using Stochastic Gradient Descent algorithm.\n",
    "\n",
    "Your homework includes 4 problems in total. Please read this notebook carefully to provide all required solutions to the problems. ( For your questions, e-mail to : ergunesr@itu.edu.tr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by reviewing Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression with Mean Squared Error and Cross Entropy Cost For Binary Linear Classification\n",
    "\n",
    "Binary classification is an instance of regression wherein the data still comes in the form of $P$ input/output pairs $\\{(\\mathbf{x}_p, y_p)\\}^{P}_{p=1}$, and each input $\\mathbf{x}_p$ is an $N$-dimensional vector. Now, the corresponding target $y_p$'s are no longer continuous but takes on only two discrete numbers. \n",
    "\n",
    "In the first problem set, you are expected to implement **two-class classification** by using Logistic Regression. Regressing a nonlinear step function to the data is called _Regression Perspective_ on classification. \n",
    "\n",
    "Denoting a linear model of $N$-dimensional input:\n",
    "\n",
    "$\\mathbf{\\widetilde{x}}^T \\mathbf{\\widetilde{w}} = b + x_1 w_1 + x_2 w_2 + \\cdots + x_N w_N$\n",
    "\n",
    "where \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$\\mathbf{\\widetilde{w}} = \\begin{bmatrix}\n",
    "b \\\\\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_{N}\n",
    "\\end{bmatrix}$\n",
    "and $\\mathbf{\\widetilde{x}} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_{N}\n",
    "\\end{bmatrix}$ . \n",
    "</div> \n",
    "\n",
    "The sigmoid function approximates the logistic regression by mapping input values to a probability between 0 and 1, enabling binary classification. The _Logistic Sigmoid Function_ is:\n",
    "<div style=\"text-align:center\">\n",
    "$\\displaystyle \\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
    "</div> \n",
    "In Logistic Regression, the following approaximate equality holds:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "   $ \\sigma(\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}) \\approx y_p, $ \n",
    "\n",
    "</div> \n",
    "where\n",
    "$p=1,...,P.$\n",
    "\n",
    "The corresponding Least Squares cost function is:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$ g(\\mathbf{\\widetilde{w}}) = \\frac {1} {P} \\sum_{p=1}^{P} (\\sigma(\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}) - y_p)^2 $\n",
    "</div> \n",
    "\n",
    "Fitting a logistic sigmoid to classification data by minimizing $ g(\\mathbf{\\widetilde{w}})$ is referred to as _logistic regression_.\n",
    "\n",
    "Thus, the value of $\\mathbf{\\widetilde{w}}$ that minimizes $g(\\mathbf{\\widetilde{w}})$ is:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$\\mathbf{\\widetilde{w}}^{*} = argmin_{\\mathbf{\\widetilde{w}}} g(\\mathbf{\\widetilde{w}}) $\n",
    "</div> \n",
    "\n",
    "In this homework, you are assigned to find $\\mathbf{\\widetilde{w}}^{*}$ with **stochastic gradient descent**. Stochastic gradient descent uses the two equations below for the two versions of Logistic Regression you will implement. \n",
    "\n",
    "\\begin{align*}\n",
    "w_{i}^{t+1} &= w_{i}^{t} - \\alpha \\frac{\\partial g(\\mathbf{\\widetilde{w}}^{t})}{\\partial w_{i}^t} \\text{ for all } i \\\\\n",
    "b^{t+1} &= b^{t} - \\alpha \\frac{\\partial g(\\mathbf{\\widetilde{w}}^t)}{\\partial b^t}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "### Logistic Regression using the Cross Entropy cost \n",
    "\n",
    "The squared error cost works for every output value $y_p$. Because we know two-class classification setting is limited to the discrete values $ y_p \\in \\{0,1\\}$, we can use more appropriate costs. \n",
    "\n",
    "_Log Error_ is defined as follows:\n",
    "<div style=\"text-align:center\">\n",
    "$$\n",
    "g(\\mathbf{\\widetilde{w}}) =\n",
    "\\begin{cases}\n",
    "    -log(\\sigma(\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}) ) & \\text{if } y_p = 1 \\\\\n",
    "    -log(1 - \\sigma(\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}) ) & \\text{if } y_p = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "</div> \n",
    "\n",
    "This representation penalizes divergence from target values much more harshly than a squared error. The equivalent form of the log error in single line, formed by taking the average over all dataset is:\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$g(\\mathbf{\\widetilde{w}}) = \\frac {1} {P} \\sum_{p=1}^{P} y_p log(\\sigma(\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}) + (1-y_p)log(1 - \\sigma(\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}})$\n",
    "</div> \n",
    "\n",
    "This is, referred to as the _Cross Entropy cost_ for logistic regression.\n",
    "\n",
    "The Cross Entropy cost function is utilized in logistic regression, offering advantages over the Least Squares method which is non-convex. Cross Entropy cost is always convex, ensuring more stable optimization. On the first problem, you are tasked with implementing Logistic Regression using both the squared error and cross entropy cost functions. \n",
    "\n",
    "## Vectorized Representation\n",
    "\n",
    "The input to the model will be provided as a matrix with one sample in each column of $\\mathbf{X}$:\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$ \\mathbf{X} = \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,P} \\\\\n",
    "x_{2,1} & x_{2,2} & \\ldots & x_{2,P} \\\\\n",
    " \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{N,1} & x_{N,2} & \\ldots & x_{N,P}\n",
    "\\end{bmatrix} $\n",
    "</div>\n",
    "\n",
    "The weight vector will be a row vector, containing:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$ \\mathbf{w} = [w_1, w_2, \\cdots , w_N ]$\n",
    "</div>\n",
    "\n",
    "And bias term will be a scalar. \n",
    "\n",
    "## Normalization\n",
    "\n",
    "Similar to Homework-2, you need to implement **MinMaxScaler** in **data_utils.py** in  **LogisticRegression.py**. (Normalization scales the features of a dataset to a consistent range, preventing dominance by features with larger scales.)\n",
    "\n",
    "## Evaluation Metrics - Accuracy, Precision, Recall, and F1 \n",
    "\n",
    "In this homework you are expected to report your models' results with commonly used classification metrics: accuracy, precision, recall, and F1.\n",
    "\n",
    "Accuracy measures the proportion of correctly identified instances among the total instances. It's calculated as the ratio of the number of correct predictions to the total number of predictions made.\n",
    "   - Formula: \n",
    "     ```\n",
    "     Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)\n",
    "     ```\n",
    "\n",
    "Recall, also known as sensitivity or true positive rate, measures the proportion of actual positive instances that were correctly identified by the model.\n",
    "   - It answers the question: \"Of all the positive instances, how many did we correctly identify?\"\n",
    "   - Formula: \n",
    "     ```\n",
    "     Recall = True Positives / (True Positives + False Negatives)\n",
    "     ```\n",
    "\n",
    "Precision measures the proportion of true positive predictions among all positive predictions made by the model.\n",
    "   - It answers the question: \"Of all the instances predicted as positive, how many are actually positive?\"\n",
    "   - Formula: \n",
    "     ```\n",
    "     Precision = True Positives / (True Positives + False Positives)\n",
    "     ```\n",
    "\n",
    "F1 score is the harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
    "   - It's particularly useful when the dataset is imbalanced.\n",
    "   - Formula:\n",
    "     ```\n",
    "     F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "     ```\n",
    "\n",
    "\n",
    "You are expected to complete the following tasks:\n",
    "\n",
    "1) Implement feature normalization class **MinMaxScaler** as instructed,\n",
    "\n",
    "2) Implement and train Logistic Regression models with Mean Squared Error and Cross Entropy Cost by using stochastic gradient descent. Plot and report the training and test accuracies, precision, recall, and F1 scores of both methods and compare the results. Write your comments in a cell.\n",
    "\n",
    "To provide your solution for Logistic regression, you need to complete the **LogisticRegression** class inside **LogisticRegression.py**  by implementing methods for initialization, sigmoid function computation, hypothesis calculation, training for binary classification with mean squared error (by stochastic gradient descent), training with cross-entropy loss (by stochastic gradient descent). The methods should handle initialization of instance variables, computation of sigmoid function, calculation of hypothesis values, iterative stochastic gradient descent updates for both mean squared error and cross-entropy loss. Please write your solutions to the designated spaces in **LogisticRegression.py** as instructed.\n",
    "\n",
    "We start by calling **generate_data()** function. You do not need to change anything related to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize our dataset as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training data\n",
    "plt.scatter(x_train[0], x_train[1], c=y_train, cmap='viridis', label='Training Data')\n",
    "# Visualize testing data\n",
    "plt.scatter(x_test[0], x_test[1], c=y_test, cmap='viridis', marker='x', label='Testing Data')\n",
    "\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Dataset Visualization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **transform** and **inverse_transform** methods are part of the **MinMaxScaler** class, which is commonly used for feature scaling and normalization. Feature scaling is important in data preprocessing to ensure that features with larger values do not dominate the model training process. The transform method scales the input data to a desired range, while the **inverse_transform** method can be used to reverse this scaling operation. By implementing these methods in the data_utils.py file, we can ensure that the input data is properly scaled and balanced, which can improve the performance of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to x_train\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# Transform x_train and x_test\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression()** class takes datasets as inputs and returns a Logistic Regression model object. This class has two training methods. **train_binary_classification()** method is for training the model with minimizing the mean squared error while **train_binary_classification_cross_entropy()** trains the model by minimizing cross entropy loss. These methods find optimal Logistic Regression model parameters $\\mathbf{\\widetilde{w}}^{*}$ by using Stochastic Gradient Descent algortihm. Please code up necessary operations inside  **LogisticRegression** module and run the following cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we will start by training Logistic Regression with MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "# Create a model instance\n",
    "model_mse = LogisticRegression(x_train_scaled, y_train, x_test_scaled, y_test)\n",
    "# Start training my calling the MSE training method.\n",
    "train_acc_mse, test_acc_mse = model_mse.train_binary_classification(iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then you may start training with Cross Entropy cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ce = LogisticRegression(x_train_scaled, y_train, x_test_scaled, y_test)\n",
    "train_acc_ce, test_acc_ce = model_ce.train_binary_classification_cross_entropy(iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the model training accuracies\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Percentage Correctly Classified')\n",
    "plt.title('Training Accuracy')\n",
    "plt.ylim([0, 100])\n",
    "plt.plot(train_acc_mse, 'r-.', label='Logistic (MSE)')\n",
    "plt.plot(train_acc_ce, 'g-', label='Logistic (Cross-Entropy)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot the model testing accuracies\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Percentage Correctly Classified')\n",
    "plt.title('Test Accuracy')\n",
    "plt.ylim([0, 105])\n",
    "plt.plot(test_acc_mse, 'r-.', label='Logistic (MSE)')\n",
    "plt.plot(test_acc_ce, 'g-', label='Logistic (Cross-Entropy)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Logistic Regression with Cross Entropy Cost (Minimization with  Stochastic Gradient Descent)\n",
    "\n",
    "### In this problem you are expected to implement SGD algorithm with Cross Entropy Cost and build a binary classification pipeline:\n",
    "\n",
    "- Implement **Stochastic Gradient Descent** algorithm for Cross Entropy Cost\n",
    "- Construct a Binary Linear Classification model with Logistic Regression and Cross Entropy Cost\n",
    "- Optimize the model parameters with Stochastic Gradient Descent. Implement hyperparameter search for learning rate and weight initialization. Report your search results. Plot Training and Testing accuracies Gradient Descent and SGD minimizations. Report and compare the performance of the models in terms of accuracy, precision, recall, and F1-scores.\n",
    "\n",
    "You have been provided with a dataset **(HW2_Q1_2.npy)** consisting of three dimensions as features and corresponding labels. You may load the dataset by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('HW2_Q1_2.npy', 'rb') as f:\n",
    "    x_train = np.load(f)\n",
    "    x_test = np.load(f)\n",
    "    y_train = np.load(f)\n",
    "    y_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Implement Stochastic Gradient Descent (SGD) algorithm in             #\n",
    "# LogisticRegression module. (For cross entropy cost)                        #\n",
    "# Perform data scaling with MinMaxScaler                                     #\n",
    "# Train the Logistic Regression model with both Gradient Descent (with Cross #\n",
    "# Entropy Cost) and SGD                                                      #\n",
    "# Plot and report the training and test accuracies, precision, recall,       #\n",
    "# and F-1s.                                                                  #\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PERCEPTRON \n",
    "\n",
    "In Problem set 1, classification was treated as a particular form of non-linear regression resulted learning a linear decision boundary:\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$\\mathbf{\\widetilde{x}}^T \\mathbf{\\widetilde{w}} = 0 .$\n",
    "</div> \n",
    "\n",
    "The Perceptron described here aims at determining this ideal linear decision boundary directly. It has a different approach than non-linear regression, the primary goal of perceptron is to separate different classes. The linear decision boundary cuts the input space into two half-spaces and our desired solution defines a hyperplane where we have:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <span>$\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}} > 0$ if $y_p = +1$</span> <br>\n",
    "    <span>$\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}} < 0$ if $y_p = -1$</span>\n",
    "</div>\n",
    "\n",
    "For this decision boundary, the cost function for the entire dataset can be written as:\n",
    "<div align=\"center\">\n",
    "$g_p(\\mathbf{\\widetilde{x}}) = \\frac{1}{P} \\sum_{p=1}^P max(0, -y_p\\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}) $\n",
    "</div>\n",
    "\n",
    "This cost function goes names such as _Perceptron cost, rectified linear unit, ReLU cost, and the hinge cost_. This function is always _convex_ except a single discontinuous derivative. Therefore, a common approach is to approximate the Perceptron cost with _Softmax_ function.\n",
    "\n",
    "_Softmax_ function is defined as:\n",
    "<div align=\"center\">\n",
    "$soft(s_0, s_1, \\cdots, s_{C-1}) = log(e^{s_0} + e^{s_1} + \\cdots + e^{s_{C-1}})$\n",
    "</div>\n",
    "\n",
    "Softmax function is a smooth approximarion to the $max$ function. Replacing the $max$ function gives the overall cost function as:\n",
    "<div align=\"center\">\n",
    "$g_p(\\mathbf{\\widetilde{x}}) = \\frac{1}{P} \\sum_{p=1}^P log(1+e^{-y_p \\mathbf{\\widetilde{x}}^T_p \\mathbf{\\widetilde{w}}})$\n",
    "    </div>\n",
    "\n",
    "This cost alleviates the difficulties of the Perceptron cost. This cost can be minimized by local optimization techniques.\n",
    "\n",
    "## 2.1 Binary MNIST classification by Perceptron with Softmax Approximation\n",
    "\n",
    "In this problem , you will implement a binary classification on 2 digits of `MNIST` dataset by training a Perceptron model. Your Perceptron model will compute loss with Softmax approximation. You are assigned to find optimal parameters $\\mathbf{\\widetilde{w}}^{*}$ that minimizes the previously introduced cost function by using iterative optimization scheme **Stochastic Gradient Descent**. To achieve that, please complete **fit sgd()** methods of **SoftmaxPerceptron** class under **SoftmaxPerceptron.py** module as instructed. You are expected to implement hyperparameter search by changing the default values and plot accuracy curves for your search, and for the best results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "# Load the MNIST training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MNIST` dataset has 60000 training and 10000 test images. Let's see the dimensions of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: torch.Size([60000, 28, 28])\n",
      "Test dataset size: torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", train_dataset.data.shape)\n",
    "print(\"Test dataset size:\", test_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample is a 28x28 image. Let's visualize one example and see what they look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/esra/anaconda3/envs/agi/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJBklEQVR4nO3dS2iV+RnH8eeZZGQaUdPQVlvbVOIioiLpQi0iOGKDWJQStYVAKEXrylAXbTbC0FoaEbxQgi6ysmhBhE7BS6VaiJeFbUrw0paAXbSdGSUDM9XjJd4a8+8iZ0oazvvEnJx4fif5fkAI/vJ63jDz5dX8OeopJQOg561y3wCAwogTEEWcgCjiBEQRJyCKOAFRxFlB3P2Ku//wTV+L8iDOMnD3f7n7t8p9H1nc/Qfu/srdn4z68W6572umqS73DUDWH1NKa8t9EzMZT04h7v55dz/v7p+4+4P8x18d82mL3f3P7v7Q3c+4e92o67/p7tfdPefut3naVTbi1PKWmR03s6+bWb2ZPTOzo2M+5/tmtsPMvmJmQ2bWZWbm7gvN7Hdm9gszqzOzn5jZ++7+xbEv4u71+YDrg3v5hrt/6u5/d/f33J3fZb1hxCkkpfTvlNL7KaWnKaXHZtZpZuvGfNrJlNLfUkqDZvaemX3P3avMrM3MLqSULqSUhlNKfzCzPjP7doHX+TClVJtS+jDjVq6Z2XIz+5KZbTOzVjPrKMkXiddGnELcvcbdu939A3d/ZCOR1Obj+8xHoz7+wMzeNrMv2MjT9rv5J2LO3XNmttbMvjzR+0gp/SOl9M985H81s5+b2fYivywUid+qaPmxmTWa2eqU0sfu3mRmN83MR33O10Z9XG9m/zGzT20k2pMppV1TcF9pzD3gDeDJWT5vu/s7o35Um9kcG/lzZi7/jZ6fFriuzd2XunuNjTzRfpNSemVmvzazLe6+0d2r8r/muwW+oTQud9/k7vPzHy+xkd8+nyny60SRiLN8LthIiJ/9+JmZ/dLMPmcjT8I/mdnvC1x30sx+ZWYfm9k7ZvYjM7OU0kdm9h0z22tmn9jIk7TDCvw3zn9D6EnwDaENZvYXdx/M3+dvzWz/xL9ETIbzZmtAE09OQBRxAqKIExBFnICo8JzT3fluETDFUkoFz5B5cgKiiBMQRZyAKOIERBEnIIo4AVHECYgiTkAUcQKiiBMQRZyAKOIERBEnIIo4AVHECYgiTkAUcQKiiBMQRZyAKOIERBEnIIo4AVHECYgiTkAUcQKiiBMQRZyAKOIERBEnIIo4AVHECYgiTkAUcQKiiBMQRZyAKOIERBEnIIo4AVHV5b4B/L+qqqpwnzdv3pS+fnt7e+ZWU1MTXtvY2Bjuu3fvDvdDhw5lbq2treG1z58/D/cDBw6E+759+8K9HHhyAqKIExBFnIAo4gREEScgijgBUcQJiOKcs4D6+vpwnzVrVrivWbMm3NeuXZu51dbWhtdu27Yt3Mvp7t274d7V1RXuLS0tmdvjx4/Da2/fvh3uV69eDXdFPDkBUcQJiCJOQBRxAqKIExBFnIAoTyllj+7ZYwVramoK956ennCf6rdtqRoeHg73HTt2hPuTJ0+Kfu2BgYFwf/DgQbjfuXOn6NeeaiklL/TzPDkBUcQJiCJOQBRxAqKIExBFnIAo4gREzchzzrq6unDv7e0N94aGhlLeTkmNd++5XC7c169fn7m9fPkyvHamnv9OFuecQIUhTkAUcQKiiBMQRZyAKOIERBEnIGpG/tWY9+/fD/eOjo5w37x5c7jfvHkz3Mf7KyIjt27dCvfm5uZwHxwcDPdly5Zlbnv27AmvRWnx5AREEScgijgBUcQJiCJOQBRxAqKIExA1I9/POVlz584N9/H+ubru7u7MbefOneG1bW1t4X7q1Klwhx7ezwlUGOIERBEnIIo4AVHECYgiTkAUcQKiZuT7OSfr0aNHk7r+4cOHRV+7a9eucD99+nS4j/dvbEIHT05AFHECoogTEEWcgCjiBEQRJyCKt4yVwezZszO3c+fOhdeuW7cu3Ddt2hTuly5dCne8ebxlDKgwxAmIIk5AFHECoogTEEWcgCjiBERxzilm8eLF4X7jxo1wz+Vy4X758uVw7+vry9yOHTsWXhv9v4RsnHMCFYY4AVHECYgiTkAUcQKiiBMQRZyAKM45K0xLS0u4Hz9+PNznzJlT9Gvv3bs33E+cOBHuAwMDRb/2dMY5J1BhiBMQRZyAKOIERBEnIIo4AVHECYjinHOaWb58ebgfOXIk3Dds2FD0a3d3d4d7Z2dnuN+7d6/o165knHMCFYY4AVHECYgiTkAUcQKiiBMQRZyAKM45Z5ja2tpw37JlS+Y23ntF3Qse1/1PT09PuDc3N4f7dMU5J1BhiBMQRZyAKOIERBEnIIo4AVEcpeC1vXjxItyrq6vDfWhoKNw3btyYuV25ciW8tpJxlAJUGOIERBEnIIo4AVHECYgiTkAUcQKi4oMpVJwVK1aE+/bt28N95cqVmdt455jj6e/vD/dr165N6tefbnhyAqKIExBFnIAo4gREEScgijgBUcQJiOKcU0xjY2O4t7e3h/vWrVvDfcGCBRO+p9f16tWrcB8YGAj34eHhUt5OxePJCYgiTkAUcQKiiBMQRZyAKOIERBEnIIpzzikw3llia2tr5jbeOeaiRYuKuaWS6OvrC/fOzs5wP3v2bClvZ9rjyQmIIk5AFHECoogTEEWcgCjiBERxlFLA/Pnzw33p0qXhfvTo0XBfsmTJhO+pVHp7e8P94MGDmduZM2fCa3nLV2nx5AREEScgijgBUcQJiCJOQBRxAqKIExA1bc856+rqMrfu7u7w2qampnBvaGgo5pZK4vr16+F++PDhcL948WK4P3v2bML3hKnBkxMQRZyAKOIERBEnIIo4AVHECYgiTkCU7Dnn6tWrw72joyPcV61albktXLiwqHsqladPn2ZuXV1d4bX79+8P98HBwaLuCXp4cgKiiBMQRZyAKOIERBEnIIo4AVHECYiSPedsaWmZ1D4Z/f394X7+/PlwHxoaCvfoPZe5XC68FjMHT05AFHECoogTEEWcgCjiBEQRJyCKOAFRnlLKHt2zRwAlkVLyQj/PkxMQRZyAKOIERBEnIIo4AVHECYgiTkAUcQKiiBMQRZyAKOIERBEnIIo4AVHECYgiTkAUcQKiiBMQRZyAKOIERBEnIIo4AVHECYgK/2pMAOXDkxMQRZyAKOIERBEnIIo4AVHECYj6L4Xh1Us+6cJ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define function to visualize a digit\n",
    "def visualize_digit(image, label):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a digit from the training dataset\n",
    "index = 0  # Choose the index of the digit to visualize\n",
    "digit_image = train_dataset.data[index]\n",
    "visualize_digit(digit_image, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a binary classification Perceptron model on `MNIST`, we will create our custom subset, which contains only digits 0 and 1. And then, we will flatten the images into vectors. Please run the following cell, you do not need to change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5923])\n",
      "torch.Size([11872])\n"
     ]
    }
   ],
   "source": [
    "# Filter train and test data for classes 0 and 1\n",
    "train_indices = torch.logical_or(train_dataset.targets == 0, train_dataset.targets == 9)\n",
    "test_indices = torch.logical_or(test_dataset.targets == 0, test_dataset.targets == 9)\n",
    "\n",
    "train_data_filtered = train_dataset.data[train_indices]\n",
    "train_labels_filtered = train_dataset.targets[train_indices]\n",
    "test_data_filtered = test_dataset.data[test_indices]\n",
    "test_labels_filtered = test_dataset.targets[test_indices]\n",
    "\n",
    "# Relabel classes 0 and 1 as 1 and -1 respectively\n",
    "train_labels_filtered[train_labels_filtered == 1] = -1\n",
    "train_labels_filtered[train_labels_filtered == 0] = 1\n",
    "test_labels_filtered[test_labels_filtered == 1] = -1\n",
    "test_labels_filtered[test_labels_filtered == 0] = 1\n",
    "\n",
    "# Flatten the images and convert them to numpy arrays\n",
    "train_data_flat = train_data_filtered.reshape(train_data_filtered.shape[0], -1).T.numpy()\n",
    "test_data_flat = test_data_filtered.reshape(test_data_filtered.shape[0], -1).T.numpy()\n",
    "train_labels_filtered = train_labels_filtered.numpy()\n",
    "test_labels_filtered = test_labels_filtered.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start constructing our classification pipeline by scaling our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import MinMaxScaler\n",
    "import numpy as np \n",
    "np.random.seed(42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "fitted = scaler.fit(train_data_flat)\n",
    "x_train_norm = scaler.transform(train_data_flat)\n",
    "x_test_norm = scaler.transform(test_data_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have train_data_flat as training set, and test_data_flat as test set. Let's check the sizes of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: (784, 11872)\n",
      "test set size: (784, 1989)\n"
     ]
    }
   ],
   "source": [
    "print(\"train set size:\", train_data_flat.shape)\n",
    "print(\"test set size:\", test_data_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you need to normalize the flattened data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import MinMaxScaler\n",
    "import numpy as np \n",
    "np.random.seed(42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "fitted = scaler.fit(train_data_flat)\n",
    "x_train_norm = scaler.transform(train_data_flat)\n",
    "x_test_norm = scaler.transform(test_data_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can construct our model by calling SoftmaxPerceptron and start training. Fit_sgd() method trains the Perceptron with Stochastic Gradient Descent algorithm. You need the complete the methods in SoftmaxPerceptron module as instructed. Implement hyperparameter search to observe the change in accuracy, and plot each curve. Plot the training and test accuracies, precisions, recalls, and F-1 scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: -Complete SoftmaxPerceptron.py module as instructed.                 #\n",
    "# -Construct a Perceptron model for binary classification where targets      #\n",
    "# are -1 or +1.                                                              #\n",
    "# -Train your model with fit_gd() method which implements gradient descent   #\n",
    "# algorithm for obtaining optimal model parameters. Implement hyperparameter #\n",
    "# search for learning rate and weight initialization.                        #\n",
    "# -Report performance in terms of accuracy.                                  #\n",
    "# Plot the training and test accuracy, recall, precision, and F-1 scores.    #\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Regularized Two-Class Classification\n",
    "\n",
    "When the dataset is perfectly linearly separable, Softmax cost faces severe numerical instability issues. There are several ways to overcome this problem and _regularization of weights_ is one of them. \n",
    "\n",
    "In this question you will implement regularization of the feature touching parameters $\\mathbf{w}$ of Perceptron model. You will implement your regularized cost minimization with Gradient Descent in **fit_gd_regularized()** method under the _SoftmaxPerceptron_ class. \n",
    "\n",
    "Feature touching weights of the perceptron model and input column vector are shown below:\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "$\\mathbf{w} = \\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_{N}\n",
    "\\end{bmatrix} $\n",
    "and $\\mathbf{x} = \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_{N}\n",
    "\\end{bmatrix}$ .\n",
    "    \n",
    "Now, we can express a linear decision boundary as:\n",
    "    \n",
    "<div style=\"text-align:center\">\n",
    "$\\mathbf{\\widetilde{x}}^T \\mathbf{\\widetilde{w}} = b + \\mathbf{x}^T \\mathbf{w} = 0.$\n",
    "</div> \n",
    "\n",
    "where $b$ is the bias. \n",
    "    \n",
    "To prevent feature touching weights from growing too large and diverging to infinity, we can constrain Softmax/Cross Entropy cost as follows:\n",
    "    \n",
    "<div align=\"center\">\n",
    "$g(b, \\mathbf{w}) = \\frac{1}{P} \\sum_{p=1}^P log(1+e^{-y_p (\\mathbf{x}^T_p \\mathbf{w}+b)})  + \\lambda \\|\\mathbf{w}\\|_2^2$\n",
    "</div>\n",
    "\n",
    "    \n",
    "Here, the term $\\|\\mathbf{w}\\|_2^2$ is referred to as _regularizer_ , and the parameter $\\lambda>0$ is called a _regularization parameter_.\n",
    "    \n",
    "As before, the goal is to find optimal bias and weight parameters $b^*$ and $\\mathbf{w}^*$ that minimize $g(b, \\mathbf{w})$. \n",
    "    \n",
    "In this question the task is creating a regularized binary classification pipeline with Perceptron model. The parameters will be found by using Gradient Descent algorithm. Specifically you need to:\n",
    "    \n",
    "1- Implement training a Perceptron model with regularization under **fit_gd_regularized()** method.\n",
    "    \n",
    "2- Load the data \"HW2_Q2_2.npy\" and scale features with MinMaxScaler.\n",
    "\n",
    "3- Set up your model and train with **fit_gd_regularized()** method. Implement hyperparameter search (Including \n",
    "   $\\lambda$) and plot training and testing accuracies. Report test set Recall, Precision, and Accuracy results. \n",
    "\n",
    "4- Implement cross validation on the training set (for folds: [2,3,...,10]) and report/plot the average performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following cell loads the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('HW2_Q2_2.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "    X_test = np.load(f)\n",
    "    y_train = np.load(f)\n",
    "    y_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: -Complete fit_gd_regularized() method as instructed.                 #\n",
    "# -Construct a Perceptron model for binary classification where targets      #\n",
    "# are -1 or +1.                                                              #\n",
    "# -Train your model with fit_gd_regularized() method which implements GD     #\n",
    "# algorithm on regularized cost function. The purpose is preventing feature  #\n",
    "# toucing weights to grow larger. Implement hyperparameter                   #\n",
    "# search for learning rate, weight initialization, and regularization        #\n",
    "# parameter lambda. Plot training and test accuracies.                       #\n",
    "# -Report performance in terms of accuracy, recall, precision, and F-1 scores#\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
